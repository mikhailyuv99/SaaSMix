# Google Colab : Cells Ã  Copier-Coller (Ã‰tape par Ã‰tape)

## ðŸŽ¯ Instructions

1. **Ouvre Google Colab** : https://colab.research.google.com
2. **CrÃ©e un nouveau notebook**
3. **Active GPU T4** : Runtime â†’ Change runtime type â†’ GPU T4
4. **Copie-colle chaque cell** ci-dessous dans l'ordre
5. **ExÃ©cute** chaque cell (Shift+Enter)

---

## ðŸ“ Cell 1 : Setup Environnement

```python
# Installer Diff-MST
!git clone https://github.com/sai-soum/Diff-MST.git
%cd Diff-MST

# Installer le package
!pip install -e .

# Installer dÃ©pendances
!pip install torch torchaudio pytorch-lightning wandb librosa soundfile pyyaml tqdm tensorboard

print("âœ“ Installation terminÃ©e!")
```

**ExÃ©cute et attends que Ã§a finisse** (2-3 minutes)

---

## ðŸ“ Cell 2 : Mount Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')

print("âœ“ Google Drive montÃ©!")
```

**ExÃ©cute et :**
- Clique sur le lien qui apparaÃ®t
- Autorise l'accÃ¨s
- Copie le code d'autorisation
- Colle-le dans la cell
- Appuie sur Enter

---

## ðŸ“ Cell 3 : PrÃ©parer Dataset

```python
import os
import zipfile

# Chemin vers dataset.zip dans Drive
dataset_zip = '/content/drive/MyDrive/dataset.zip'
dataset_dir = '/content/dataset'

# DÃ©compresser si pas dÃ©jÃ  fait
if not os.path.exists(dataset_dir):
    print("DÃ©compression du dataset...")
    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
        zip_ref.extractall('/content')
    print("âœ“ Dataset dÃ©compressÃ©!")
else:
    print("âœ“ Dataset dÃ©jÃ  prÃ©sent!")

# VÃ©rifier
raw_dir = '/content/dataset/raw'
mixed_dir = '/content/dataset/mixed'

if os.path.exists(raw_dir) and os.path.exists(mixed_dir):
    raw_count = len([f for f in os.listdir(raw_dir) if f.endswith('.wav')])
    mixed_count = len([f for f in os.listdir(mixed_dir) if f.endswith('.wav')])
    print(f"âœ“ Raw: {raw_count} fichiers")
    print(f"âœ“ Mixed: {mixed_count} fichiers")
    
    if raw_count == mixed_count and raw_count == 222:
        print("âœ… Dataset parfait! 222 paires prÃªtes.")
    else:
        print(f"âš ï¸  Attendu 222, trouvÃ© {raw_count} raw et {mixed_count} mixed")
else:
    print("âŒ Dossiers raw/mixed introuvables!")
    print(f"   CherchÃ© dans: {raw_dir} et {mixed_dir}")
```

**ExÃ©cute et vÃ©rifie** qu'il affiche "222 paires prÃªtes"

---

## ðŸ“ Cell 4 : VÃ©rifier GPU

```python
import torch

print(f"CUDA disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    print("âœ… GPU prÃªt pour l'entraÃ®nement!")
else:
    print("âš ï¸  Pas de GPU - Active GPU T4 dans Runtime â†’ Change runtime type")
```

**ExÃ©cute et vÃ©rifie** qu'il affiche "GPU: Tesla T4" (ou similaire)

---

## ðŸ“ Cell 5 : Explorer Diff-MST

```python
# Explorer la structure de Diff-MST
import os

print("Structure Diff-MST:")
print("="*60)
mst_dir = '/content/Diff-MST'
if os.path.exists(mst_dir):
    for item in sorted(os.listdir(mst_dir)):
        item_path = os.path.join(mst_dir, item)
        if os.path.isdir(item_path) and not item.startswith('.'):
            print(f"ðŸ“ {item}/")
            # Lister quelques fichiers Python
            py_files = [f for f in os.listdir(item_path) if f.endswith('.py')][:3]
            for f in py_files:
                print(f"   - {f}")
        elif item.endswith('.py'):
            print(f"ðŸ“„ {item}")

print("\n" + "="*60)
print("Modules importants:")
print("  - mst/modules/ : Architecture du modÃ¨le")
print("  - mst/mixing/ : Console de mixing")
print("  - mst/dataloaders/ : Chargeurs de donnÃ©es")
```

**ExÃ©cute pour voir la structure**

---

## ðŸ“ Cell 6 : CrÃ©er DataLoader Custom

```python
# CrÃ©er le dossier pour notre DataLoader
!mkdir -p /content/Diff-MST/mst/dataloaders

# CrÃ©er le fichier vocal_reference_dataset.py
vocal_loader_code = '''
"""
DataLoader pour vocal mixing avec reference mix
Adapte Diff-MST pour single track vocal
"""
import os
import torch
from torch.utils.data import Dataset
import librosa
import numpy as np
from typing import List, Tuple
import random

class VocalReferenceDataset(Dataset):
    """Dataset pour vocal mixing avec reference"""
    
    def __init__(
        self,
        raw_dir: str,
        mixed_dir: str,
        sample_rate: int = 48000,
        segment_length: int = 192000,  # 4 secondes Ã  48kHz
        augment: bool = True
    ):
        self.raw_dir = raw_dir
        self.mixed_dir = mixed_dir
        self.sample_rate = sample_rate
        self.segment_length = segment_length
        self.augment = augment
        
        # Trouver les paires
        self.pairs = self._find_pairs()
        print(f"Found {len(self.pairs)} vocal pairs")
    
    def _find_pairs(self) -> List[Tuple[str, str]]:
        """Trouve les paires raw/mixed"""
        pairs = []
        raw_files = {f for f in os.listdir(self.raw_dir) if f.endswith('.wav')}
        mixed_files = {f for f in os.listdir(self.mixed_dir) if f.endswith('.wav')}
        
        for filename in sorted(raw_files):
            if filename in mixed_files:
                pairs.append((
                    os.path.join(self.raw_dir, filename),
                    os.path.join(self.mixed_dir, filename)
                ))
        return pairs
    
    def _load_audio(self, path: str) -> np.ndarray:
        """Charge audio en mono"""
        audio, sr = librosa.load(path, sr=self.sample_rate, mono=True)
        return audio
    
    def __len__(self):
        return len(self.pairs)
    
    def __getitem__(self, idx):
        raw_path, mixed_path = self.pairs[idx]
        
        # Charger
        raw = self._load_audio(raw_path)
        mixed = self._load_audio(mixed_path)
        
        # Extraire segments (mÃªme position pour raw et mixed)
        min_len = min(len(raw), len(mixed))
        if min_len <= self.segment_length:
            # Pad si trop court
            raw_seg = np.zeros(self.segment_length)
            mixed_seg = np.zeros(self.segment_length)
            raw_seg[:len(raw)] = raw
            mixed_seg[:len(mixed)] = mixed
        else:
            # Segment alÃ©atoire (mÃªme position)
            max_start = min_len - self.segment_length
            start = random.randint(0, max_start) if self.augment else 0
            raw_seg = raw[start:start + self.segment_length]
            mixed_seg = mixed[start:start + self.segment_length]
        
        # Convertir en tensor [batch, channels, samples]
        # Pour Diff-MST : [1, 1, samples] (1 track, 1 channel)
        raw_tensor = torch.FloatTensor(raw_seg).unsqueeze(0).unsqueeze(0)
        mixed_tensor = torch.FloatTensor(mixed_seg).unsqueeze(0).unsqueeze(0)
        
        return {
            'tracks': raw_tensor,  # Piste Ã  mixer
            'reference': mixed_tensor  # Reference mix (target)
        }
'''

# Ã‰crire le fichier
with open('/content/Diff-MST/mst/dataloaders/vocal_reference_dataset.py', 'w') as f:
    f.write(vocal_loader_code)

print("âœ“ DataLoader custom crÃ©Ã©!")
print("   Fichier: /content/Diff-MST/mst/dataloaders/vocal_reference_dataset.py")
```

**ExÃ©cute cette cell**

---

## â¸ï¸ Pause : Explorer Diff-MST

**Avant de continuer, on doit comprendre comment Diff-MST fonctionne pour l'adapter.**

**Dis-moi quand tu as exÃ©cutÃ© les cells 1-6, et on explore ensemble le code Diff-MST pour voir exactement ce qu'il faut adapter.**

---

## ðŸ“‹ Checklist

- [ ] Cell 1 exÃ©cutÃ©e (Installation)
- [ ] Cell 2 exÃ©cutÃ©e (Drive montÃ©)
- [ ] Cell 3 exÃ©cutÃ©e (Dataset dÃ©compressÃ©, 222 paires)
- [ ] Cell 4 exÃ©cutÃ©e (GPU T4 actif)
- [ ] Cell 5 exÃ©cutÃ©e (Structure explorÃ©e)
- [ ] Cell 6 exÃ©cutÃ©e (DataLoader crÃ©Ã©)

**Quand tout est fait, dis-moi et on continue avec l'adaptation de Diff-MST !**
