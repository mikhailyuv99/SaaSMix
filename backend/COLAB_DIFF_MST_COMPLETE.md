# Google Colab : Fine-Tuning Diff-MST pour Vocal Mixing

## ðŸŽ¯ Objectif

Fine-tuner Diff-MST avec tes **222 paires** dans Google Colab (GPU gratuit).

---

## ðŸ“‹ PrÃ©requis

- âœ… Compte Google (pour Colab)
- âœ… Dataset prÃªt : 222 paires dans `C:\Users\mikha\Desktop\dataset`
- âœ… Google Drive (pour sauvegarder le dataset)

---

## ðŸš€ Ã‰tape 1 : PrÃ©parer le Dataset pour Colab

### Option A : Upload vers Google Drive (RecommandÃ©)

1. **CrÃ©er un fichier ZIP** de ton dataset :
   ```powershell
   # Sur ton PC
   cd C:\Users\mikha\Desktop
   Compress-Archive -Path dataset -DestinationPath dataset.zip
   ```

2. **Upload `dataset.zip` vers Google Drive** :
   - Va sur https://drive.google.com
   - Upload `dataset.zip` dans `MyDrive`

3. **Dans Colab**, on le dÃ©compressera automatiquement

### Option B : Upload Direct dans Colab

- Plus lent mais plus simple
- On upload les fichiers directement dans Colab

---

## ðŸš€ Ã‰tape 2 : CrÃ©er le Notebook Colab

### CrÃ©er un Nouveau Notebook

1. Va sur https://colab.research.google.com
2. **File â†’ New notebook**
3. Nomme-le : "Diff-MST Vocal Mixing"

---

## ðŸ“ Cell 1 : Setup Environnement

```python
# Installer Diff-MST
!git clone https://github.com/sai-soum/Diff-MST.git
%cd Diff-MST

# Installer le package
!pip install -e .

# Installer dÃ©pendances
!pip install torch torchaudio pytorch-lightning wandb librosa soundfile pyyaml tqdm tensorboard

print("âœ“ Installation terminÃ©e!")
```

**ExÃ©cute cette cell** (Runtime â†’ Run cell ou Shift+Enter)

---

## ðŸ“ Cell 2 : Mount Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')

print("âœ“ Google Drive montÃ©!")
```

**ExÃ©cute et autorise l'accÃ¨s** quand demandÃ©.

---

## ðŸ“ Cell 3 : PrÃ©parer Dataset

```python
import os
import zipfile

# Chemin vers dataset.zip dans Drive
dataset_zip = '/content/drive/MyDrive/dataset.zip'
dataset_dir = '/content/dataset'

# DÃ©compresser si pas dÃ©jÃ  fait
if not os.path.exists(dataset_dir):
    print("DÃ©compression du dataset...")
    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
        zip_ref.extractall('/content')
    print("âœ“ Dataset dÃ©compressÃ©!")
else:
    print("âœ“ Dataset dÃ©jÃ  prÃ©sent!")

# VÃ©rifier
raw_dir = '/content/dataset/raw'
mixed_dir = '/content/dataset/mixed'

if os.path.exists(raw_dir) and os.path.exists(mixed_dir):
    raw_count = len([f for f in os.listdir(raw_dir) if f.endswith('.wav')])
    mixed_count = len([f for f in os.listdir(mixed_dir) if f.endswith('.wav')])
    print(f"âœ“ Raw: {raw_count} fichiers")
    print(f"âœ“ Mixed: {mixed_count} fichiers")
else:
    print("âŒ Dossiers raw/mixed introuvables!")
```

**ExÃ©cute cette cell** et vÃ©rifie que Ã§a affiche 222 fichiers.

---

## ðŸ“ Cell 4 : CrÃ©er DataLoader Custom pour Vocal Mixing

```python
# CrÃ©er le dossier pour notre DataLoader
!mkdir -p /content/Diff-MST/mst/dataloaders

# CrÃ©er le fichier vocal_reference_dataset.py
vocal_loader_code = '''
"""
DataLoader pour vocal mixing avec reference mix
Adapte Diff-MST pour single track vocal
"""
import os
import torch
from torch.utils.data import Dataset
import librosa
import numpy as np
from typing import List, Tuple
import random

class VocalReferenceDataset(Dataset):
    """Dataset pour vocal mixing avec reference"""
    
    def __init__(
        self,
        raw_dir: str,
        mixed_dir: str,
        sample_rate: int = 48000,
        segment_length: int = 192000,  # 4 secondes Ã  48kHz
        augment: bool = True
    ):
        self.raw_dir = raw_dir
        self.mixed_dir = mixed_dir
        self.sample_rate = sample_rate
        self.segment_length = segment_length
        self.augment = augment
        
        # Trouver les paires
        self.pairs = self._find_pairs()
        print(f"Found {len(self.pairs)} vocal pairs")
    
    def _find_pairs(self) -> List[Tuple[str, str]]:
        """Trouve les paires raw/mixed"""
        pairs = []
        raw_files = {f for f in os.listdir(self.raw_dir) if f.endswith('.wav')}
        mixed_files = {f for f in os.listdir(self.mixed_dir) if f.endswith('.wav')}
        
        for filename in sorted(raw_files):
            if filename in mixed_files:
                pairs.append((
                    os.path.join(self.raw_dir, filename),
                    os.path.join(self.mixed_dir, filename)
                ))
        return pairs
    
    def _load_audio(self, path: str) -> np.ndarray:
        """Charge audio en mono"""
        audio, sr = librosa.load(path, sr=self.sample_rate, mono=True)
        return audio
    
    def __len__(self):
        return len(self.pairs)
    
    def __getitem__(self, idx):
        raw_path, mixed_path = self.pairs[idx]
        
        # Charger
        raw = self._load_audio(raw_path)
        mixed = self._load_audio(mixed_path)
        
        # Extraire segments (mÃªme position pour raw et mixed)
        min_len = min(len(raw), len(mixed))
        if min_len <= self.segment_length:
            # Pad si trop court
            raw_seg = np.zeros(self.segment_length)
            mixed_seg = np.zeros(self.segment_length)
            raw_seg[:len(raw)] = raw
            mixed_seg[:len(mixed)] = mixed
        else:
            # Segment alÃ©atoire (mÃªme position)
            max_start = min_len - self.segment_length
            start = random.randint(0, max_start) if self.augment else 0
            raw_seg = raw[start:start + self.segment_length]
            mixed_seg = mixed[start:start + self.segment_length]
        
        # Convertir en tensor [batch, channels, samples]
        # Pour Diff-MST : [1, 1, samples] (1 track, 1 channel)
        raw_tensor = torch.FloatTensor(raw_seg).unsqueeze(0).unsqueeze(0)
        mixed_tensor = torch.FloatTensor(mixed_seg).unsqueeze(0).unsqueeze(0)
        
        return {
            'tracks': raw_tensor,  # Piste Ã  mixer
            'reference': mixed_tensor  # Reference mix (target)
        }
'''

# Ã‰crire le fichier
with open('/content/Diff-MST/mst/dataloaders/vocal_reference_dataset.py', 'w') as f:
    f.write(vocal_loader_code)

print("âœ“ DataLoader custom crÃ©Ã©!")
```

**ExÃ©cute cette cell.**

---

## ðŸ“ Cell 5 : Explorer Diff-MST (Comprendre la Structure)

```python
# Explorer la structure de Diff-MST
import os

print("Structure Diff-MST:")
for root, dirs, files in os.walk('/content/Diff-MST'):
    level = root.replace('/content/Diff-MST', '').count(os.sep)
    indent = ' ' * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = ' ' * 2 * (level + 1)
    for file in files[:5]:  # Afficher max 5 fichiers par dossier
        if file.endswith('.py'):
            print(f"{subindent}{file}")

# Lire le README
print("\n" + "="*60)
print("README Diff-MST:")
print("="*60)
with open('/content/Diff-MST/README.md', 'r') as f:
    print(f.read()[:2000])  # Premiers 2000 caractÃ¨res
```

**ExÃ©cute pour comprendre la structure.**

---

## ðŸ“ Cell 6 : VÃ©rifier GPU

```python
import torch

print(f"CUDA disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
else:
    print("âš ï¸ Pas de GPU - Training sera trÃ¨s lent sur CPU")
```

**Important :** Active le GPU dans Colab :
- **Runtime â†’ Change runtime type â†’ GPU (T4)**

---

## âš ï¸ Prochaine Ã‰tape : Adapter Diff-MST

**Avant de continuer, on doit :**

1. âœ… Explorer le code Diff-MST (voir comment il fonctionne)
2. âœ… Comprendre comment adapter pour single track
3. âœ… CrÃ©er le script de training adaptÃ©

**Je vais crÃ©er les cells suivantes une fois qu'on a explorÃ© Diff-MST.**

---

## ðŸŽ¯ Plan d'Action

### Maintenant

1. âœ… **CrÃ©er le notebook Colab**
2. âœ… **ExÃ©cuter les cells 1-6** (setup, dataset, exploration)
3. âœ… **Explorer Diff-MST** pour comprendre l'adaptation

### Ensuite

4. âœ… **Adapter Diff-MST** pour vocal mixing
5. âœ… **CrÃ©er le script de training**
6. âœ… **Lancer le fine-tuning**

---

## ðŸ’¡ Alternative : Commencer Simple

**Si l'adaptation Diff-MST est trop complexe :**

On peut d'abord **rÃ©entraÃ®ner notre modÃ¨le actuel avec 222 paires** :
- âœ… Plus simple
- âœ… On connaÃ®t dÃ©jÃ  le code
- âœ… QualitÃ© probablement trÃ¨s bonne avec 7.7x plus de donnÃ©es
- âœ… On peut tester rapidement

**Puis migrer vers Diff-MST plus tard si besoin.**

---

## ðŸš€ On Commence ?

**Actions immÃ©diates :**

1. **CrÃ©er le notebook Colab** (https://colab.research.google.com)
2. **Copier les cells 1-6** ci-dessus
3. **ExÃ©cuter** et me dire ce qui se passe
4. **On explore Diff-MST** ensemble pour l'adapter

**Tu veux que je te guide cell par cell, ou tu prÃ©fÃ¨res que je crÃ©e un notebook complet prÃªt Ã  copier-coller ?**
