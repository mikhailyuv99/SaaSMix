{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff-MST Fine-Tuning pour Vocal Mixing\n",
    "\n",
    "Fine-tuner Diff-MST avec 222 paires de vocal mixing (single track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 : Setup Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer Diff-MST\n",
    "!git clone https://github.com/sai-soum/Diff-MST.git\n",
    "%cd Diff-MST\n",
    "\n",
    "# Installer le package\n",
    "!pip install -e .\n",
    "\n",
    "# Installer dÃ©pendances\n",
    "!pip install torch torchaudio pytorch-lightning wandb librosa soundfile pyyaml tqdm tensorboard\n",
    "\n",
    "print(\"âœ“ Installation terminÃ©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 : Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ“ Google Drive montÃ©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 : PrÃ©parer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Chemin vers dataset.zip dans Drive\n",
    "dataset_zip = '/content/drive/MyDrive/dataset.zip'\n",
    "dataset_dir = '/content/dataset'\n",
    "\n",
    "# DÃ©compresser si pas dÃ©jÃ  fait\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"DÃ©compression du dataset...\")\n",
    "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content')\n",
    "    print(\"âœ“ Dataset dÃ©compressÃ©!\")\n",
    "else:\n",
    "    print(\"âœ“ Dataset dÃ©jÃ  prÃ©sent!\")\n",
    "\n",
    "# VÃ©rifier\n",
    "raw_dir = '/content/dataset/raw'\n",
    "mixed_dir = '/content/dataset/mixed'\n",
    "\n",
    "if os.path.exists(raw_dir) and os.path.exists(mixed_dir):\n",
    "    raw_count = len([f for f in os.listdir(raw_dir) if f.endswith('.wav')])\n",
    "    mixed_count = len([f for f in os.listdir(mixed_dir) if f.endswith('.wav')])\n",
    "    print(f\"âœ“ Raw: {raw_count} fichiers\")\n",
    "    print(f\"âœ“ Mixed: {mixed_count} fichiers\")\n",
    "    \n",
    "    if raw_count == mixed_count and raw_count == 222:\n",
    "        print(\"âœ… Dataset parfait! 222 paires prÃªtes.\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Attendu 222, trouvÃ© {raw_count} raw et {mixed_count} mixed\")\n",
    "else:\n",
    "    print(\"âŒ Dossiers raw/mixed introuvables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 : VÃ©rifier GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  Pas de GPU - Active GPU T4 dans Runtime â†’ Change runtime type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 : Explorer Diff-MST (Comprendre la Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorer la structure de Diff-MST\n",
    "import os\n",
    "\n",
    "print(\"Structure Diff-MST:\")\n",
    "for root, dirs, files in os.walk('/content/Diff-MST'):\n",
    "    level = root.replace('/content/Diff-MST', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:3]:  # Afficher max 3 fichiers par dossier\n",
    "        if file.endswith('.py'):\n",
    "            print(f\"{subindent}{file}\")\n",
    "\n",
    "# Lire le README\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"README Diff-MST:\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    with open('/content/Diff-MST/README.md', 'r') as f:\n",
    "        print(f.read()[:1500])  # Premiers 1500 caractÃ¨res\n",
    "except:\n",
    "    print(\"README non trouvÃ©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 : CrÃ©er DataLoader Custom pour Vocal Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er le dossier pour notre DataLoader\n",
    "!mkdir -p /content/Diff-MST/mst/dataloaders\n",
    "\n",
    "# CrÃ©er le fichier vocal_reference_dataset.py\n",
    "vocal_loader_code = '''\"\"\"\n",
    "DataLoader pour vocal mixing avec reference mix\n",
    "Adapte Diff-MST pour single track vocal\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "\n",
    "class VocalReferenceDataset(Dataset):\n",
    "    \"\"\"Dataset pour vocal mixing avec reference\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        raw_dir: str,\n",
    "        mixed_dir: str,\n",
    "        sample_rate: int = 48000,\n",
    "        segment_length: int = 192000,  # 4 secondes Ã  48kHz\n",
    "        augment: bool = True\n",
    "    ):\n",
    "        self.raw_dir = raw_dir\n",
    "        self.mixed_dir = mixed_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.segment_length = segment_length\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Trouver les paires\n",
    "        self.pairs = self._find_pairs()\n",
    "        print(f\"Found {len(self.pairs)} vocal pairs\")\n",
    "    \n",
    "    def _find_pairs(self) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Trouve les paires raw/mixed\"\"\"\n",
    "        pairs = []\n",
    "        raw_files = {f for f in os.listdir(self.raw_dir) if f.endswith('.wav')}\n",
    "        mixed_files = {f for f in os.listdir(self.mixed_dir) if f.endswith('.wav')}\n",
    "        \n",
    "        for filename in sorted(raw_files):\n",
    "            if filename in mixed_files:\n",
    "                pairs.append((\n",
    "                    os.path.join(self.raw_dir, filename),\n",
    "                    os.path.join(self.mixed_dir, filename)\n",
    "                ))\n",
    "        return pairs\n",
    "    \n",
    "    def _load_audio(self, path: str) -> np.ndarray:\n",
    "        \"\"\"Charge audio en mono\"\"\"\n",
    "        audio, sr = librosa.load(path, sr=self.sample_rate, mono=True)\n",
    "        return audio\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raw_path, mixed_path = self.pairs[idx]\n",
    "        \n",
    "        # Charger\n",
    "        raw = self._load_audio(raw_path)\n",
    "        mixed = self._load_audio(mixed_path)\n",
    "        \n",
    "        # Extraire segments (mÃªme position pour raw et mixed)\n",
    "        min_len = min(len(raw), len(mixed))\n",
    "        if min_len <= self.segment_length:\n",
    "            # Pad si trop court\n",
    "            raw_seg = np.zeros(self.segment_length)\n",
    "            mixed_seg = np.zeros(self.segment_length)\n",
    "            raw_seg[:len(raw)] = raw\n",
    "            mixed_seg[:len(mixed)] = mixed\n",
    "        else:\n",
    "            # Segment alÃ©atoire (mÃªme position)\n",
    "            max_start = min_len - self.segment_length\n",
    "            start = random.randint(0, max_start) if self.augment else 0\n",
    "            raw_seg = raw[start:start + self.segment_length]\n",
    "            mixed_seg = mixed[start:start + self.segment_length]\n",
    "        \n",
    "        # Convertir en tensor [batch, channels, samples]\n",
    "        # Pour Diff-MST : [1, 1, samples] (1 track, 1 channel)\n",
    "        raw_tensor = torch.FloatTensor(raw_seg).unsqueeze(0).unsqueeze(0)\n",
    "        mixed_tensor = torch.FloatTensor(mixed_seg).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        return {\n",
    "            'tracks': raw_tensor,  # Piste Ã  mixer\n",
    "            'reference': mixed_tensor  # Reference mix (target)\n",
    "        }\n",
    "'''\n",
    "\n",
    "# Ã‰crire le fichier\n",
    "with open('/content/Diff-MST/mst/dataloaders/vocal_reference_dataset.py', 'w') as f:\n",
    "    f.write(vocal_loader_code)\n",
    "\n",
    "print(\"âœ“ DataLoader custom crÃ©Ã©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 : Explorer le Code Diff-MST (Identifier ce qu'il faut adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorer les modules principaux de Diff-MST\n",
    "import os\n",
    "\n",
    "print(\"Modules Diff-MST:\")\n",
    "mst_dir = '/content/Diff-MST/mst'\n",
    "if os.path.exists(mst_dir):\n",
    "    for item in os.listdir(mst_dir):\n",
    "        item_path = os.path.join(mst_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"  ðŸ“ {item}/\")\n",
    "            # Lister quelques fichiers\n",
    "            files = [f for f in os.listdir(item_path) if f.endswith('.py')][:3]\n",
    "            for f in files:\n",
    "                print(f\"     - {f}\")\n",
    "        elif item.endswith('.py'):\n",
    "            print(f\"  ðŸ“„ {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Prochaines Ã©tapes:\")\n",
    "print(\"1. Explorer les modules 'mixing' et 'modules'\")\n",
    "print(\"2. Comprendre comment Diff-MST fonctionne\")\n",
    "print(\"3. Adapter pour single track vocal\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
