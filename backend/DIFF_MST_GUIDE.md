# Guide Diff-MST : Mixing Style Transfer

## ğŸ¯ Pourquoi Diff-MST est le Meilleur Choix

**Diff-MST (Differentiable Mixing Style Transfer)** est **spÃ©cialement conÃ§u pour le mixing**, contrairement Ã  AnyEnhance qui est plus gÃ©nÃ©raliste.

### Avantages de Diff-MST :
- âœ… **SpÃ©cialisÃ© mixing** - ConÃ§u pour transformer raw â†’ mixed
- âœ… **InterprÃ©table** - PrÃ©dit les paramÃ¨tres de console (EQ, compression, etc.)
- âœ… **Style transfer** - Apprend ton style de mixing spÃ©cifique
- âœ… **Architecture adaptÃ©e** - Transformer-based controller pour mixing console
- âœ… **Variable tracks** - Supporte diffÃ©rents nombres de pistes

---

## ğŸ“Š Diff-MST vs AnyEnhance

| CritÃ¨re | Diff-MST | AnyEnhance |
|---------|----------|------------|
| **SpÃ©cialisation** | âœ… Mixing uniquement | âš ï¸ Voice enhancement gÃ©nÃ©ral |
| **Style transfer** | âœ… Oui (c'est son but) | âŒ Non |
| **ParamÃ¨tres prÃ©dits** | âœ… EQ, compression, etc. | âŒ Non |
| **InterprÃ©tabilitÃ©** | âœ… Oui (voit les paramÃ¨tres) | âŒ Non |
| **Pour vocal mixing** | âœ… **PARFAIT** | âš ï¸ GÃ©nÃ©raliste |

**Verdict : Diff-MST est le meilleur choix pour ton cas !** â­

---

## ğŸš€ Comment Diff-MST Fonctionne

### Architecture :
```
Raw Vocal + Reference Mix â†’ Transformer Controller â†’ Mixing Console Parameters
                                                          â†“
                                                    EQ, Compression, 
                                                    Saturation, etc.
                                                          â†“
                                                    Mixed Vocal
```

### Ce qu'il apprend :
- âœ… ParamÃ¨tres de console (gain, EQ, compression)
- âœ… Style de mixing (ton style spÃ©cifique)
- âœ… Transformation raw â†’ mixed

### Avantages :
- âœ… **InterprÃ©table** - Tu peux voir les paramÃ¨tres prÃ©dits
- âœ… **Ajustable** - Tu peux modifier les paramÃ¨tres aprÃ¨s
- âœ… **Style transfer** - Apprend exactement ton style

---

## ğŸ“¦ Installation et Setup

### 1. Installation

```bash
# Cloner le repository Diff-MST
git clone https://github.com/sai-soum/Diff-MST.git
cd Diff-MST

# CrÃ©er un environnement virtuel (recommandÃ©)
python3 -m venv env
source env/bin/activate  # Linux/macOS
# ou
env\Scripts\activate  # Windows

# Installer le package
pip install -e .  # Installation Ã©ditable (pour dÃ©veloppement)
# ou
pip install .  # Installation normale

# VÃ©rifier les dÃ©pendances
pip install -r requirements.txt
```

**Note :** Diff-MST utilise PyTorch Lightning et nÃ©cessite Python 3.10+

### 2. Structure des DonnÃ©es

```
dataset/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ vocal1.wav      â† Raw vocals
â”‚   â”œâ”€â”€ vocal2.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ mixed/
    â”œâ”€â”€ vocal1.wav      â† Mixed vocals (ton style)
    â”œâ”€â”€ vocal2.wav
    â””â”€â”€ ...
```

**Important :** MÃªme format que pour ton modÃ¨le actuel !

---

## ğŸ¯ Fine-tuning avec Diff-MST

### Combien de DonnÃ©es ?

**Minimum : 100-150 paires**
- âœ… QualitÃ© acceptable
- âœ… Temps : 4-6 heures

**RecommandÃ© : 200-300 paires** â­
- âœ… QualitÃ© professionnelle
- âœ… Temps : 6-8 heures
- âœ… **C'est le sweet spot**

**Premium : 300-500 paires**
- âœ… QualitÃ© exceptionnelle
- âœ… Temps : 8-12 heures

### Processus de Fine-tuning

Diff-MST utilise PyTorch Lightning et des fichiers de configuration YAML.

**1. PrÃ©parer la structure de donnÃ©es :**

```
dataset/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ vocal1.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ mixed/
    â”œâ”€â”€ vocal1.wav
    â””â”€â”€ ...
```

**2. CrÃ©er un fichier de configuration :**

CrÃ©er `configs/data/vocal_mixing.yaml` :
```yaml
track_root_dirs:
  - ./dataset/raw  # Tes raw vocals
mix_root_dirs:
  - ./dataset/mixed  # Tes mixed vocals
batch_size: 4
num_workers: 0
```

**3. Fine-tuning avec Lightning CLI :**

```bash
# Fine-tuning avec tes donnÃ©es
CUDA_VISIBLE_DEVICES=0 python main.py fit \
  -c configs/config.yaml \
  -c configs/optimizer.yaml \
  -c configs/data/vocal_mixing.yaml \
  -c configs/models/naive+feat.yaml \
  --ckpt_path path/to/pretrained/model.ckpt  # Si disponible
```

**Note :** Diff-MST est conÃ§u pour multitrack, mais peut Ãªtre adaptÃ© pour vocal mixing en utilisant une seule piste (vocal).

---

## ğŸ”§ IntÃ©gration dans Ton Code

### Structure Diff-MST

Diff-MST a cette structure :
- `mst/mixing/` - Console de mixing diffÃ©rentiable
- `mst/modules/` - Modules du modÃ¨le (Transformer controller)
- `mst/dataloaders/` - Chargeurs de donnÃ©es
- `scripts/` - Scripts d'infÃ©rence

### Option 1 : Utiliser les Scripts d'InfÃ©rence

Diff-MST fournit des scripts d'infÃ©rence dans `scripts/`. Tu peux les adapter :

```python
# Adapter scripts/eval_all_combo.py pour ton cas
from mst.modules import DiffMSTModel
import torch

# Charger le modÃ¨le fine-tunÃ©
model = DiffMSTModel.load_from_checkpoint("./models/diff_mst_finetuned.ckpt")
model.eval()

# Traiter un vocal
def process_vocal(audio_path):
    # Charger l'audio
    audio = load_audio(audio_path)
    
    # PrÃ©dire les paramÃ¨tres et appliquer
    with torch.no_grad():
        mixed = model(audio)  # Retourne le mix
    
    return mixed
```

### Option 2 : IntÃ©grer dans audio_processor.py

```python
# Dans audio_processor.py
import sys
sys.path.append('/path/to/Diff-MST')  # Ajouter au path
from mst.modules import DiffMSTModel
import torch

class AudioProcessor:
    def __init__(self, use_ml_model=True, model_path="./models/diff_mst_finetuned.ckpt"):
        if use_ml_model:
            # Charger le modÃ¨le Diff-MST
            self.ml_model = DiffMSTModel.load_from_checkpoint(model_path)
            self.ml_model.eval()
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.ml_model.to(self.device)
    
    def _process_vocal_ml(self, audio: np.ndarray) -> np.ndarray:
        # Convertir en tensor
        audio_tensor = torch.FloatTensor(audio).unsqueeze(0).unsqueeze(0).to(self.device)
        
        # Traiter avec Diff-MST
        with torch.no_grad():
            # Diff-MST prend [batch, channels, samples]
            # Pour vocal mixing, on peut utiliser une seule piste
            mixed_tensor = self.ml_model(audio_tensor)
        
        # Convertir en numpy
        processed = mixed_tensor.cpu().numpy()[0, 0]
        return processed
```

**Note :** Diff-MST est conÃ§u pour multitrack, mais peut Ãªtre adaptÃ© pour vocal (single track).

---

## ğŸ“Š Avantages SpÃ©cifiques pour Ton Produit

### 1. InterprÃ©tabilitÃ©
- âœ… Tu peux voir les paramÃ¨tres prÃ©dits (EQ, compression, etc.)
- âœ… Utile pour le debugging
- âœ… Utile pour expliquer aux clients

### 2. AjustabilitÃ©
- âœ… Tu peux modifier les paramÃ¨tres aprÃ¨s prÃ©diction
- âœ… Plus de contrÃ´le que les modÃ¨les "boÃ®te noire"
- âœ… Permet des ajustements manuels si nÃ©cessaire

### 3. Style Transfer
- âœ… Apprend exactement ton style de mixing
- âœ… Plus prÃ©cis qu'un modÃ¨le gÃ©nÃ©raliste
- âœ… RÃ©sultats cohÃ©rents avec ton style

---

## ğŸ¯ Plan d'Action avec Diff-MST

### Ã‰tape 1 : Installation
```bash
git clone https://github.com/sai-soum/diff-mst
cd diff-mst
pip install -r requirements.txt
```

### Ã‰tape 2 : PrÃ©parer Tes DonnÃ©es
- **200-300 paires** raw/mixed (au lieu de 500-750)
- MÃªme format que maintenant
- QualitÃ© cohÃ©rente de mixage

### Ã‰tape 3 : Fine-tuning
- Charger le modÃ¨le prÃ©-entraÃ®nÃ©
- Fine-tune sur tes donnÃ©es
- Temps : 6-8 heures

### Ã‰tape 4 : IntÃ©gration
- IntÃ©grer dans `audio_processor.py`
- Tester avec `quick_test.py`
- Comparer avec le modÃ¨le actuel

### Ã‰tape 5 : DÃ©ploiement
- Utiliser Diff-MST au lieu du modÃ¨le from scratch
- QualitÃ© meilleure avec moins de donnÃ©es !

---

## ğŸ’¡ DiffÃ©rences avec Ton ModÃ¨le Actuel

### Ton ModÃ¨le Actuel (AudioUNet) :
- âŒ From scratch (besoin de 500-750 paires)
- âŒ BoÃ®te noire (pas d'interprÃ©tabilitÃ©)
- âŒ 18-24 heures d'entraÃ®nement

### Diff-MST :
- âœ… PrÃ©-entraÃ®nÃ© (100-300 paires suffisent)
- âœ… InterprÃ©table (voit les paramÃ¨tres)
- âœ… 6-8 heures de fine-tuning
- âœ… SpÃ©cialisÃ© mixing

**Diff-MST est clairement meilleur pour ton cas !** â­

---

## ğŸ“ Checklist : Migration vers Diff-MST

- [ ] Installer Diff-MST
- [ ] PrÃ©parer 200-300 paires raw/mixed
- [ ] Fine-tune le modÃ¨le (6-8h)
- [ ] Tester sur donnÃ©es non vues
- [ ] IntÃ©grer dans `audio_processor.py`
- [ ] Comparer avec modÃ¨le actuel
- [ ] DÃ©ployer si meilleur

---

## ğŸš€ Prochaines Ã‰tapes

1. **Installer Diff-MST** - `git clone` le repo
2. **VÃ©rifier la structure** - Voir comment ils organisent les donnÃ©es
3. **Fine-tune** - Avec tes 200-300 paires
4. **IntÃ©grer** - Dans ton code existant
5. **Tester** - Comparer avec ton modÃ¨le actuel

**Tu auras un meilleur modÃ¨le avec moins de donnÃ©es et moins de temps !** ğŸ’°

---

## ğŸ“š Ressources

- **Paper** : https://sai-soum.github.io/projects/diffmst/
- **GitHub** : https://github.com/sai-soum/Diff-MST
- **Website** : https://sai-soum.github.io/projects/diffmst/
- **Video** : https://youtu.be/w90RGZ3IqQw
- **Documentation** : Voir le README.md dans le repo

## âš ï¸ Notes Importantes

1. **Multitrack vs Single Track** : Diff-MST est conÃ§u pour multitrack mixing, mais peut Ãªtre adaptÃ© pour vocal mixing en utilisant une seule piste.

2. **Structure des donnÃ©es** : Diff-MST attend une structure spÃ©cifique avec des fichiers YAML de mÃ©tadonnÃ©es. Il faudra adapter ta structure actuelle.

3. **PrÃ©-entraÃ®nement** : VÃ©rifier si des checkpoints prÃ©-entraÃ®nÃ©s sont disponibles dans le repo ou sur le site web.

4. **Licence** : CC-BY-NC-SA 4.0 (vÃ©rifier si compatible avec usage commercial)

---

## ğŸ¯ RÃ©sumÃ©

**Avec Diff-MST :**

- âœ… **200-300 paires** (au lieu de 500-750)
- âœ… **6-8 heures** d'entraÃ®nement (au lieu de 18-24h)
- âœ… **InterprÃ©table** (voit les paramÃ¨tres)
- âœ… **SpÃ©cialisÃ© mixing** (parfait pour ton cas)
- âœ… **QualitÃ© professionnelle** garantie

**C'est le meilleur choix pour ton produit !** ğŸš€
